{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 876
    },
    "executionInfo": {
     "elapsed": 26627,
     "status": "ok",
     "timestamp": 1751348211112,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "tTrgEg9JfF2R",
    "outputId": "b50296ed-64c1-4dd4-99ff-935232778de2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=ae1096528565d9b89eaf1a6fffd21b57d79def7fded1db2caab6a76de5cb92b2\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: numpy, scipy, rouge-score, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.3\n",
      "    Uninstalling scipy-1.15.3:\n",
      "      Successfully uninstalled scipy-1.15.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 rouge-score-0.1.2 scipy-1.13.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "a5a65dfb839a44c09d94a5186f5eeaff",
       "pip_warning": {
        "packages": [
         "numpy",
         "scipy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install gensim nltk rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26655,
     "status": "ok",
     "timestamp": 1751348293575,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "je3hdR1Pfb_F",
    "outputId": "293ca3cb-2bfc-47fb-d476-2c970194f026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/M Tech/Sem3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7078,
     "status": "ok",
     "timestamp": 1751348224185,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "tb44RknddM_L",
    "outputId": "7c8d7921-2dc8-48b4-db61-ef6ffd13e458"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 502915,
     "status": "ok",
     "timestamp": 1751348805788,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "rMriWApQe04L"
   },
   "outputs": [],
   "source": [
    "w2v_path = \"Embeddings/cc.hi.300.vec\"\n",
    "w2v_model = KeyedVectors.load_word2vec_format(w2v_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1751348876837,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "6v7fZW39fWYT"
   },
   "outputs": [],
   "source": [
    "def sentence_vector(sentence, model):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    word_vecs = [model[word] for word in words if word in model]\n",
    "    return np.mean(word_vecs, axis=0) if word_vecs else np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1751348878205,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "OO-7kufHfsWO"
   },
   "outputs": [],
   "source": [
    "def load_dataset(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        raw = json.load(f)\n",
    "    samples = []\n",
    "    for domain in raw[\"domains\"]:\n",
    "        for item in domain[\"contexts\"]:\n",
    "            context = item[\"context\"]\n",
    "            for qa in item[\"qas\"]:\n",
    "                samples.append({\n",
    "                    \"id\": qa[\"id\"],\n",
    "                    \"context\": context,\n",
    "                    \"question\": qa[\"question\"],\n",
    "                    \"answer\": qa[\"answer\"]\n",
    "                })\n",
    "    return pd.DataFrame(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1751348921185,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "qJae95ScfsQR"
   },
   "outputs": [],
   "source": [
    "def predict_answer(context, question):\n",
    "    sentences = sent_tokenize(context)\n",
    "    sentence_vecs = [sentence_vector(sent, w2v_model) for sent in sentences]\n",
    "    q_vec = sentence_vector(question, w2v_model)\n",
    "    similarities = cosine_similarity([q_vec], sentence_vecs)[0]\n",
    "\n",
    "    return sentences[np.argmax(similarities)]\n",
    "\n",
    "def calculate_metrics(samples):\n",
    "\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "    f1s, bleus, rougels = [], [], []\n",
    "\n",
    "    for _, row in samples.iterrows():\n",
    "        pred = row['predicted']\n",
    "        true = row['answer']\n",
    "\n",
    "        # F1\n",
    "        pred_tokens = word_tokenize(pred)\n",
    "        true_tokens = word_tokenize(true)\n",
    "        common = set(pred_tokens) & set(true_tokens)\n",
    "        if len(pred_tokens) == 0 or len(true_tokens) == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            precision = len(common) / len(pred_tokens)\n",
    "            recall = len(common) / len(true_tokens)\n",
    "            f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        f1s.append(f1)\n",
    "\n",
    "        # BLEU\n",
    "        bleus.append(sentence_bleu([true_tokens], pred_tokens, smoothing_function=smoothie))\n",
    "\n",
    "        # ROUGE-L\n",
    "        rouge = scorer.score(true, pred)\n",
    "        rougels.append(rouge['rougeL'].fmeasure)\n",
    "\n",
    "    return {\n",
    "        \"F1\": np.mean(f1s),\n",
    "        \"BLEU\": np.mean(bleus),\n",
    "        \"ROUGE-L\": np.mean(rougels)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1751348996103,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "dky1-7p7iNQV",
    "outputId": "5f6195bc-54c6-40d2-941d-c24c7ff5bda0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 25455,
     "status": "ok",
     "timestamp": 1751349740137,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "sYbpPx_ifsKN"
   },
   "outputs": [],
   "source": [
    "df = load_dataset(\"Dataset/train.json\")\n",
    "df[\"predicted\"] = df.apply(lambda row: predict_answer(row[\"context\"], row[\"question\"]), axis=1)\n",
    "\n",
    "df.to_csv(\"Embeddings/Word2Vec_results_train.csv\", index=False, encoding='utf-8')\n",
    "df[[\"id\", \"question\", \"answer\", \"predicted\"]].to_json(\"results.json\", force_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18411,
     "status": "ok",
     "timestamp": 1751349758532,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "Wf8ap8sKfsAZ",
    "outputId": "136c9c74-1990-4a86-bcf9-b9b4eae6ce8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "F1: 0.2672\n",
      "BLEU: 0.1141\n",
      "ROUGE-L: 0.2272\n"
     ]
    }
   ],
   "source": [
    "# Print Evaluation\n",
    "metrics = calculate_metrics(df)\n",
    "print(\"Evaluation Metrics:\")\n",
    "\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xu5s5td4k3tN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 4644,
     "status": "ok",
     "timestamp": 1751349763179,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "SsGLDAgQk0jt"
   },
   "outputs": [],
   "source": [
    "df = load_dataset(\"Dataset/validation.json\")\n",
    "df[\"predicted\"] = df.apply(lambda row: predict_answer(row[\"context\"], row[\"question\"]), axis=1)\n",
    "\n",
    "df.to_csv(\"Embeddings/Word2Vec_results_val.csv\", index=False, encoding='utf-8')\n",
    "df[[\"id\", \"question\", \"answer\", \"predicted\"]].to_json(\"results.json\", force_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3583,
     "status": "ok",
     "timestamp": 1751349598215,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "G-qQhDKIk0jx",
    "outputId": "5cd2eb32-0e52-4656-a268-7ab249abcdc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "F1: 0.2668\n",
      "BLEU: 0.1144\n",
      "ROUGE-L: 0.2190\n"
     ]
    }
   ],
   "source": [
    "# Print Evaluation\n",
    "metrics = calculate_metrics(df)\n",
    "print(\"Evaluation Metrics:\")\n",
    "\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mmtl35Z2k38w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXCNteE0k44Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjUe_wCFk5Cd"
   },
   "outputs": [],
   "source": [
    "df = load_dataset(\"Dataset/test-A-gold.json\")\n",
    "df[\"predicted\"] = df.apply(lambda row: predict_answer(row[\"context\"], row[\"question\"]), axis=1)\n",
    "\n",
    "df.to_csv(\"Embeddings/Word2Vec_results_test.csv\", index=False, encoding='utf-8')\n",
    "df[[\"id\", \"question\", \"answer\", \"predicted\"]].to_json(\"results.json\", force_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3583,
     "status": "ok",
     "timestamp": 1751349598215,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "DrwrQ5CNk5Cd",
    "outputId": "5cd2eb32-0e52-4656-a268-7ab249abcdc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "F1: 0.2668\n",
      "BLEU: 0.1144\n",
      "ROUGE-L: 0.2190\n"
     ]
    }
   ],
   "source": [
    "# Print Evaluation\n",
    "metrics = calculate_metrics(df)\n",
    "print(\"Evaluation Metrics:\")\n",
    "\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6RL6mimT+Ox9jXcve8Xmz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
