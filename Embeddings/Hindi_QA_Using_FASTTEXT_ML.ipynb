{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7728,
     "status": "ok",
     "timestamp": 1751308120056,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "u2bHpuwQDe0I",
    "outputId": "3a285a82-ee61-4cdd-beb7-e5b068b597d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas scikit-learn tqdm nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1751308606542,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "pKmV3Js_IJPq",
    "outputId": "3bd195a1-bc89-4338-c7a6-b021ea10d593"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18887,
     "status": "ok",
     "timestamp": 1751307379161,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "gvQg9uy0DHgl",
    "outputId": "0d736953-3531-4c81-bc8e-b8423d88c511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSXpU94jDW2j"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/M Tech/Sem3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "isHVkS8XHdMu"
   },
   "outputs": [],
   "source": [
    "def load_and_flatten(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    samples = []\n",
    "    for domain in data[\"domains\"]:\n",
    "        for ctx in domain[\"contexts\"]:\n",
    "            context = ctx[\"context\"]\n",
    "            for qa in ctx[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                answer_text = qa[\"answer\"]\n",
    "                answer_start = context.find(answer_text)\n",
    "                if answer_start == -1:\n",
    "                    continue\n",
    "                samples.append({\n",
    "                    \"id\": qa[\"id\"],\n",
    "                    \"context\": context,\n",
    "                    \"question\": question,\n",
    "                    \"answer_text\": answer_text,\n",
    "                    \"answer_start\": answer_start\n",
    "                })\n",
    "    return samples\n",
    "\n",
    "train_data = load_and_flatten(\"Dataset/train.json\")\n",
    "val_data = load_and_flatten(\"Dataset/validation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228763,
     "status": "ok",
     "timestamp": 1751309527437,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "8c81oSr6IMBq",
    "outputId": "18d1b748-b3a3-434a-f7dd-99cf70f668c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1876654it [03:48, 8203.98it/s] \n"
     ]
    }
   ],
   "source": [
    "def load_fasttext_embeddings(path):\n",
    "    embedding_index = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f):\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            try:\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                embedding_index[word] = vector\n",
    "            except:\n",
    "                continue\n",
    "    return embedding_index\n",
    "\n",
    "embedding_path = \"Embeddings/cc.hi.300.vec\"\n",
    "embedding_index = load_fasttext_embeddings(embedding_path)\n",
    "embedding_dim = len(next(iter(embedding_index.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "my3txnV9LDrT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quHue5zuImYk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzY-ax4-LEd5"
   },
   "outputs": [],
   "source": [
    "def text_to_vector(text, embeddings, dim):\n",
    "    tokens = word_tokenize(text)\n",
    "    vecs = [embeddings[tok] for tok in tokens if tok in embeddings]\n",
    "    if vecs:\n",
    "        return np.mean(vecs, axis=0)\n",
    "    else:\n",
    "        return np.zeros(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3257,
     "status": "ok",
     "timestamp": 1751309547868,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "UObFUFOGLEVJ",
    "outputId": "22dbecc0-c8ef-47bf-a123-63a6b5b0540e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1773/1773 [00:02<00:00, 606.21it/s]\n",
      "100%|██████████| 395/395 [00:00<00:00, 1211.12it/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(samples, embeddings, dim):\n",
    "    X, y = [], []\n",
    "    for sample in tqdm(samples):\n",
    "        c_vec = text_to_vector(sample[\"context\"], embeddings, dim)\n",
    "        q_vec = text_to_vector(sample[\"question\"], embeddings, dim)\n",
    "        X.append(np.concatenate([c_vec, q_vec]))\n",
    "        y.append(sample[\"answer_start\"])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = prepare_dataset(train_data, embedding_index, embedding_dim)\n",
    "X_val, y_val = prepare_dataset(val_data, embedding_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1751309550252,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "8HB_jofULHwG",
    "outputId": "0697ef46-de96-482f-8193-6ee70c7547cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 341.1457214355469\n"
     ]
    }
   ],
   "source": [
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"MSE:\", mean_squared_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1751309552150,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "u5VjSyt9LHoi",
    "outputId": "22f42f35-0128-4ef0-af75-a687abdf0a68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Accuracy: 0.06329113924050633\n"
     ]
    }
   ],
   "source": [
    "def evaluate_exact(samples, y_pred):\n",
    "    correct = 0\n",
    "    for i, sample in enumerate(samples):\n",
    "        context = sample[\"context\"]\n",
    "        true_ans = sample[\"answer_text\"]\n",
    "        pred_start = int(round(y_pred[i]))\n",
    "        pred_text = context[pred_start:pred_start + len(true_ans)]\n",
    "\n",
    "        if pred_text == true_ans:\n",
    "            correct += 1\n",
    "    return correct / len(samples)\n",
    "\n",
    "exact_match = evaluate_exact(val_data, y_pred)\n",
    "print(\"Exact Match Accuracy:\", exact_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12810,
     "status": "ok",
     "timestamp": 1751309593694,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "5PYwJjbzL3Bz",
    "outputId": "1edaa584-183f-43be-a00c-8b8bf8d0125a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.0.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=0772fe3bd32dd564cb3c9281bfc85564f1317d1d08b65cdb6d2f5a830769df66\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 461,
     "status": "ok",
     "timestamp": 1751309607678,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "DA6KQg7DLHh-",
    "outputId": "5cf2015f-fe55-4998-f6d4-684310cc6aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.65237867784357\n",
      "ROUGE-L: 0.3383966244725738\n",
      "F1 Score: 0.677714580353205\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def calculate_metrics(samples, y_pred):\n",
    "    bleu_scores, rouge_l_scores, f1_scores = [], [], []\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    smooth_fn = SmoothingFunction().method4\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        context = sample['context']\n",
    "        gold = sample['answer_text']\n",
    "        pred_start = int(round(y_pred[i]))\n",
    "        pred = context[pred_start:pred_start + len(gold)]\n",
    "\n",
    "        # Tokenize\n",
    "        gold_tokens = word_tokenize(gold)\n",
    "        pred_tokens = word_tokenize(pred)\n",
    "\n",
    "        # BLEU\n",
    "        bleu = sentence_bleu([gold_tokens], pred_tokens, smoothing_function=smooth_fn)\n",
    "        bleu_scores.append(bleu)\n",
    "\n",
    "        # ROUGE-L\n",
    "        rouge = scorer.score(gold, pred)['rougeL'].fmeasure\n",
    "        rouge_l_scores.append(rouge)\n",
    "\n",
    "        # F1 (token-level)\n",
    "        common = set(gold_tokens) & set(pred_tokens)\n",
    "        if len(common) == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            precision = len(common) / len(pred_tokens)\n",
    "            recall = len(common) / len(gold_tokens)\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return {\n",
    "        \"BLEU\": np.mean(bleu_scores),\n",
    "        \"ROUGE-L\": np.mean(rouge_l_scores),\n",
    "        \"F1\": np.mean(f1_scores)\n",
    "    }\n",
    "\n",
    "# Compute metrics\n",
    "metrics = calculate_metrics(val_data, y_pred)\n",
    "print(\"BLEU:\", metrics[\"BLEU\"])\n",
    "print(\"ROUGE-L:\", metrics[\"ROUGE-L\"])\n",
    "print(\"F1 Score:\", metrics[\"F1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105,
     "status": "ok",
     "timestamp": 1751311004146,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "eOVbPzrBRKif",
    "outputId": "96616458-7ad3-43e3-8271-99f529248319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to GLOVE_val_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_predictions_to_csv(samples, y_pred, path=\"predictions.csv\"):\n",
    "    data = []\n",
    "    for i, sample in enumerate(samples):\n",
    "        context = sample[\"context\"]\n",
    "        question = sample[\"question\"]\n",
    "        gold = sample[\"answer_text\"]\n",
    "        pred_start = int(round(y_pred[i]))\n",
    "        pred_ans = context[pred_start:pred_start + len(gold)]\n",
    "\n",
    "        data.append({\n",
    "            \"id\": sample[\"id\"],\n",
    "            \"question\": question,\n",
    "            \"context\": context,\n",
    "            \"gold_answer\": gold,\n",
    "            \"predicted_answer\": pred_ans,\n",
    "            \"predicted_start\": pred_start\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Saved predictions to {path}\")\n",
    "\n",
    "save_predictions_to_csv(val_data, y_pred, path=\"Embeddings/GLOVE_val_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1751311091911,
     "user": {
      "displayName": "Ankur Jariwala",
      "userId": "00684332072584272390"
     },
     "user_tz": -330
    },
    "id": "dAFCOOV5RNe9",
    "outputId": "34a2a713-0dce-4ff1-c18e-4063a353c2ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to Glove\\GLOVE_val_predictions.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def save_predictions_to_json(samples, y_pred, path=\"val_predictions.json\"):\n",
    "    output = []\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        context = sample[\"context\"]\n",
    "        question = sample[\"question\"]\n",
    "        gold = sample[\"answer_text\"]\n",
    "        pred_start = int(round(y_pred[i]))\n",
    "        pred_ans = context[pred_start:pred_start + len(gold)]\n",
    "\n",
    "        output.append({\n",
    "            \"id\": sample[\"id\"],\n",
    "            \"question\": question,\n",
    "            \"context\": context,\n",
    "            \"gold_answer\": gold,\n",
    "            \"predicted_answer\": pred_ans,\n",
    "            \"predicted_start\": pred_start\n",
    "        })\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Saved predictions to {path}\")\n",
    "\n",
    "save_predictions_to_json(val_data, y_pred, path=\"Embeddings/GLOVE_val_predictions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iu2G-4XyRocG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNznLTWe4gbxQB4/bxKruDN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
