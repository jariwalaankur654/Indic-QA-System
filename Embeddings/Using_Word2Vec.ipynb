{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim nltk rouge-score scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co4ZDojeokUw",
        "outputId": "8af3d3e1-57c9-41db-b75a-fedcf40c0ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfThxd4ioZAv"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import f1_score\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gubRdBkLpYc8",
        "outputId": "4e359257-bde6-4955-90e7-e2a4399a9962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive\")"
      ],
      "metadata": {
        "id": "obyF6IFqptA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFR1rbbMogJF",
        "outputId": "8b779ed3-a3d6-4289-fef5-88f4b5eb14bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Split Hindi context using danda (।) ---\n",
        "def split_hindi_sentences(text):\n",
        "    return [s.strip() for s in re.split(r'।+', text) if s.strip()]\n",
        "\n",
        "# --- Load Hindi QA Dataset and convert to DataFrame ---\n",
        "def load_custom_format(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    examples = []\n",
        "    for domain in data['domains']:\n",
        "        for context_obj in domain['contexts']:\n",
        "            context = context_obj['context']\n",
        "            for qa in context_obj['qas']:\n",
        "                question = qa['question']\n",
        "                answer_text = qa['answer']\n",
        "                answer_start = context.find(answer_text)\n",
        "\n",
        "                if answer_start == -1:\n",
        "                    continue  # skip samples where answer not found in context\n",
        "\n",
        "                examples.append({\n",
        "                    'id': qa['id'],\n",
        "                    'context': context,\n",
        "                    'question': question,\n",
        "                    'answer_text': answer_text,\n",
        "                    'answer_start': answer_start\n",
        "                })\n",
        "    return pd.DataFrame(examples)"
      ],
      "metadata": {
        "id": "FPyFJnezojYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Train Word2Vec model on all context sentences ---\n",
        "def train_word2vec(df):\n",
        "    tokenized_sentences = []\n",
        "    for context in df['context']:\n",
        "        sentences = split_hindi_sentences(context)\n",
        "        tokenized_sentences.extend([word_tokenize(sent) for sent in sentences])\n",
        "    model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "    return model\n",
        "\n",
        "# --- Generate sentence vector by averaging word vectors ---\n",
        "def sentence_vector(sentence, model):\n",
        "    words = word_tokenize(sentence)\n",
        "    vecs = [model.wv[word] for word in words if word in model.wv]\n",
        "    return np.mean(vecs, axis=0) if vecs else np.zeros(model.vector_size)\n",
        "\n",
        "# --- Cosine similarity between two dense vectors ---\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:\n",
        "        return 0\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
      ],
      "metadata": {
        "id": "0MKt8yXYpM9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVCK1-xEq0lV",
        "outputId": "a4f1db77-2bc4-4268-b998-f6579b2b22fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Get best matching sentence from context for a question ---\n",
        "def get_best_answer(context, question, model):\n",
        "    sentences = split_hindi_sentences(context)\n",
        "    q_vec = sentence_vector(question, model)\n",
        "    max_sim, best_sent = -1, \"\"\n",
        "    for sent in sentences:\n",
        "        s_vec = sentence_vector(sent, model)\n",
        "        sim = cosine_similarity(q_vec, s_vec)\n",
        "        if sim > max_sim:\n",
        "            max_sim = sim\n",
        "            best_sent = sent\n",
        "    return best_sent\n",
        "\n",
        "# --- Evaluate with F1, BLEU, ROUGE-L (fuzzy F1 included) ---\n",
        "def evaluate(df, predictions):\n",
        "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "    smooth_fn = SmoothingFunction().method1\n",
        "\n",
        "    f1s, bleus, rouges, exacts = [], [], [], []\n",
        "\n",
        "    for gold, pred in zip(df['answer_text'], predictions):\n",
        "        # Fuzzy F1\n",
        "        gold_tokens = set(gold.split())\n",
        "        pred_tokens = set(pred.split())\n",
        "        common = gold_tokens.intersection(pred_tokens)\n",
        "        f1 = (2 * len(common)) / (len(gold_tokens) + len(pred_tokens)) if gold_tokens and pred_tokens else 0\n",
        "        f1s.append(f1)\n",
        "\n",
        "        # BLEU\n",
        "        bleu = sentence_bleu([gold.split()], pred.split(), smoothing_function=smooth_fn)\n",
        "        bleus.append(bleu)\n",
        "\n",
        "        # ROUGE-L\n",
        "        rouge = scorer.score(gold, pred)['rougeL'].fmeasure\n",
        "        rouges.append(rouge)\n",
        "\n",
        "        # Exact Match (substring)\n",
        "        exact = int(gold in pred)\n",
        "        exacts.append(exact)\n",
        "\n",
        "    print(\"\\n--- Evaluation ---\")\n",
        "    print(f\"Fuzzy F1 Score:     {sum(f1s)/len(f1s):.4f}\")\n",
        "    print(f\"BLEU Score:         {sum(bleus)/len(bleus):.4f}\")\n",
        "    print(f\"ROUGE-L Score:      {sum(rouges)/len(rouges):.4f}\")\n",
        "    print(f\"Exact Match Score:  {sum(exacts)/len(exacts):.4f}\")"
      ],
      "metadata": {
        "id": "i_ve-Bi3pN7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Load training data\n",
        "    train_df = load_custom_format(\"dataset/train.json\")\n",
        "\n",
        "    # Train Word2Vec model on all contexts\n",
        "    model = train_word2vec(train_df)\n",
        "\n",
        "    # Predict answers\n",
        "    predictions = []\n",
        "    for _, row in train_df.iterrows():\n",
        "        pred = get_best_answer(row['context'], row['question'], model)\n",
        "        predictions.append(pred)\n",
        "\n",
        "    # Show some predictions\n",
        "    for i in range(3):\n",
        "        print(f\"\\nQ: {train_df.iloc[i]['question']}\")\n",
        "        print(f\"A (True): {train_df.iloc[i]['answer_text']}\")\n",
        "        print(f\"A (Pred): {predictions[i]}\")\n",
        "\n",
        "    # Evaluate predictions\n",
        "    evaluate(train_df, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vmiUjbTt9DQ",
        "outputId": "d24ab9d8-2f05-41c8-faaf-274874537e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: भागीरथ कुंड पं. दीन दयाल उपाध्याय रेलवे स्टेशन से कितना किलोमीटर दूर है?\n",
            "A (True): भागीरथ कुंड पं. दीन दयाल उपाध्याय रेलवे स्टेशन से 14.1 किलोमीटर दूर है।\n",
            "A (Pred): भागीरथ कुंड पं. दीन दयाल उपाध्याय रेलवे स्टेशन से 14.1 किलोमीटर दूर है\n",
            "\n",
            "Q: क्या मणिकर्णिका कुंड में शुद्ध पेय जल की सुविधा उपलब्ध है?\n",
            "A (True): नहीं, मणिकर्णिका कुंड में शुद्ध पेय जल की सुविधा उपलब्ध नहीं है।\n",
            "A (Pred): नहीं, मणिकर्णिका कुंड में शुद्ध पेय जल की सुविधा उपलब्ध नहीं है\n",
            "\n",
            "Q: दुर्गा कुंड वाराणसी रेलवे स्टेशन (कैंट) से कितनी दूरी है?\n",
            "A (True): दुर्गा कुंड वाराणसी रेलवे स्टेशन (कैंट) से लगभग 5.9 किलोमीटर दूर स्थित है।\n",
            "A (Pred): दुर्गा कुंड वाराणसी रेलवे स्टेशन (कैंट) से लगभग 5.9 किलोमीटर दूर स्थित है\n",
            "\n",
            "--- Evaluation ---\n",
            "Fuzzy F1 Score:     0.8393\n",
            "BLEU Score:         0.7923\n",
            "ROUGE-L Score:      0.4123\n",
            "Exact Match Score:  0.0017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Load training data\n",
        "    val_df = load_custom_format(\"dataset/validation.json\")\n",
        "\n",
        "    # Train Word2Vec model on all contexts\n",
        "    model = train_word2vec(val_df)\n",
        "\n",
        "    # Predict answers\n",
        "    predictions = []\n",
        "    for _, row in val_df.iterrows():\n",
        "        pred = get_best_answer(row['context'], row['question'], model)\n",
        "        predictions.append(pred)\n",
        "\n",
        "    # Show some predictions\n",
        "    for i in range(3):\n",
        "        print(f\"\\nQ: {val_df.iloc[i]['question']}\")\n",
        "        print(f\"A (True): {val_df.iloc[i]['answer_text']}\")\n",
        "        print(f\"A (Pred): {predictions[i]}\")\n",
        "\n",
        "    # Evaluate predictions\n",
        "    evaluate(val_df, predictions)"
      ],
      "metadata": {
        "id": "oh1CxPI_ru1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Load training data\n",
        "    test_df = load_custom_format(\"dataset/test-A-gold.json\")\n",
        "\n",
        "    # Train Word2Vec model on all contexts\n",
        "    model = train_word2vec(test_df)\n",
        "\n",
        "    # Predict answers\n",
        "    predictions = []\n",
        "    for _, row in test_df.iterrows():\n",
        "        pred = get_best_answer(row['context'], row['question'], model)\n",
        "        predictions.append(pred)\n",
        "\n",
        "    # Show some predictions\n",
        "    for i in range(3):\n",
        "        print(f\"\\nQ: {test_df.iloc[i]['question']}\")\n",
        "        print(f\"A (True): {test_df.iloc[i]['answer_text']}\")\n",
        "        print(f\"A (Pred): {predictions[i]}\")\n",
        "\n",
        "    # Evaluate predictions\n",
        "    evaluate(test_df, predictions)"
      ],
      "metadata": {
        "id": "pGUCx0SZvG5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Load training data\n",
        "    test_df = load_custom_format(\"dataset/test-B.json\")\n",
        "\n",
        "    # Train Word2Vec model on all contexts\n",
        "    model = train_word2vec(test_df)\n",
        "\n",
        "    # Predict answers\n",
        "    predictions = []\n",
        "    for _, row in test_df.iterrows():\n",
        "        pred = get_best_answer(row['context'], row['question'], model)\n",
        "        predictions.append(pred)\n",
        "\n",
        "    # Show some predictions\n",
        "    for i in range(3):\n",
        "        print(f\"\\nQ: {test_df.iloc[i]['question']}\")\n",
        "        # print(f\"A (True): {test_df.iloc[i]['answer_text']}\")\n",
        "        print(f\"A (Pred): {predictions[i]}\")"
      ],
      "metadata": {
        "id": "WspsU29lvXT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd867b08-4900-4c26-c3b9-11f8f7c8204c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: आदिकेशव कुंड किन नदियों के संगम पर स्थित है और इसका धार्मिक महत्व क्या है?\n",
            "A (Pred): आदिकेशव कुंड, जो वाराणसी के प्राचीन राजघाट के निकट स्थित है, वरुणा एवं गंगा नदियों के पावन संगम स्थल पर स्थित एक अत्यंत धार्मिक और सांस्कृतिक दृष्टि से महत्त्वपूर्ण स्थान है\n",
            "\n",
            "Q: आदिकेशव कुंड का संबंध किस देवता से है और श्रद्धालु यहाँ क्यों आते हैं?\n",
            "A (Pred): श्रद्धालु इस कुंड में स्नान कर आत्मशुद्धि की अभिलाषा रखते हैं तथा इसे वाराणसी की समृद्ध ऐतिहासिक एवं धार्मिक विरासत का अनिवार्य अंग मानते हैं\n",
            "\n",
            "Q: आदिकेशव कुंड को वाराणसी की धार्मिक विरासत में कैसे देखा जाता है?\n",
            "A (Pred): यह स्थल वाराणसी की ऐतिहासिक और धार्मिक धरोहर का हिस्सा है\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWB7GL7IsoQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_data = None"
      ],
      "metadata": {
        "id": "pnyVGLlFrGt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/dataset/test-B.json', 'r', encoding='utf-8') as f:\n",
        "    json_data = json.load(f)"
      ],
      "metadata": {
        "id": "nhmzUFSRsozB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "\n",
        "domains = json_data['domains']\n",
        "for domain in domains:\n",
        "    domain_name = domain['domain']\n",
        "    for context in domain['contexts']:\n",
        "        for qa in context['qas']:\n",
        "            qa['answer'] = predictions[count]\n",
        "            count += 1"
      ],
      "metadata": {
        "id": "1FgpQ37kswCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modified_json = json.dumps(json_data)"
      ],
      "metadata": {
        "id": "ld6ln1cTs2En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Word2Vec\")"
      ],
      "metadata": {
        "id": "_EqMD6ops3fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"Word2Vec-Test-B-answered.json\", \"w\", encoding=\"utf-8\") as jf:\n",
        "    json.dump(json_data, jf, indent=2, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "VIkr7LEfs9mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-CsklL1ZtBrO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}